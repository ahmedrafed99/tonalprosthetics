units: 128
activation: relu
l2_value: 0.01
dropout_rate: 0.5
learning_rate: 0.001
epochs: 10
test_size: 0.2
random_state: 42
